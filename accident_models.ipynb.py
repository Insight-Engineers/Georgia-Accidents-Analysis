{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Georgia Traffic Accidents - Comprehensive Predictive Modeling\n",
        "\n",
        "This notebook contains multiple predictive models for accident severity prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                            accuracy_score, precision_recall_fscore_support,\n",
        "                            roc_auc_score, roc_curve)\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# For imbalanced data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"georgia_accidents.csv\")\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Engineering - Create temporal features\n",
        "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
        "df['Hour'] = df['Start_Time'].dt.hour\n",
        "df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
        "df['Month'] = df['Start_Time'].dt.month\n",
        "df['IsRushHour'] = df['Hour'].isin([7,8,9,16,17,18]).astype(int)\n",
        "df['IsWeekend'] = df['DayOfWeek'].isin([5,6]).astype(int)\n",
        "\n",
        "# Create binary target (High Severity = 3 or 4, Low Severity = 1 or 2)\n",
        "df['High_Severity'] = (df['Severity'] >= 3).astype(int)\n",
        "\n",
        "print(\"Feature engineering complete!\")\n",
        "print(f\"\\nNew features added: Hour, DayOfWeek, Month, IsRushHour, IsWeekend, High_Severity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Target Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"TARGET DISTRIBUTION\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nOriginal Severity Distribution:\")\n",
        "print(df['Severity'].value_counts().sort_index())\n",
        "print(\"\\nBinary High Severity Distribution:\")\n",
        "print(df['High_Severity'].value_counts())\n",
        "print(f\"\\nHigh Severity Rate: {df['High_Severity'].mean():.2%}\")\n",
        "\n",
        "# Visualize distributions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Original severity\n",
        "df['Severity'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "axes[0].set_title('Original Severity Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Severity Level')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Binary severity\n",
        "df['High_Severity'].value_counts().plot(kind='bar', ax=axes[1], color='coral')\n",
        "axes[1].set_title('Binary Severity Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Severity (0=Low, 1=High)')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_xticklabels(['Low (1-2)', 'High (3-4)'], rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define features to use\n",
        "features = [\n",
        "    # Weather features\n",
        "    \"Temperature(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\",\n",
        "    \"Wind_Speed(mph)\", \"Precipitation(in)\",\n",
        "    \n",
        "    # Location/distance\n",
        "    \"Distance(mi)\",\n",
        "    \n",
        "    # Road features (boolean)\n",
        "    \"Traffic_Signal\", \"Junction\", \"Crossing\", \"Stop\", \"Station\",\n",
        "    \"Amenity\", \"Bump\", \"Give_Way\", \"Railway\", \"Roundabout\",\n",
        "    \n",
        "    # Temporal features\n",
        "    \"Hour\", \"DayOfWeek\", \"Month\", \"IsRushHour\", \"IsWeekend\",\n",
        "    \n",
        "    # Categorical\n",
        "    \"Sunrise_Sunset\", \"Weather_Condition\"\n",
        "]\n",
        "\n",
        "X = df[features].copy()\n",
        "y_multiclass = df['Severity']  # For multiclass models\n",
        "y_binary = df['High_Severity']  # For binary classification\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FEATURES SELECTED\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total features: {len(features)}\")\n",
        "print(f\"Numeric features: {X.select_dtypes(include=[np.number]).shape[1]}\")\n",
        "print(f\"Categorical/Boolean features: {X.select_dtypes(include=['object', 'bool']).shape[1]}\")\n",
        "print(f\"\\nFeatures list:\")\n",
        "for i, f in enumerate(features, 1):\n",
        "    print(f\"{i:2d}. {f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Preprocessing Pipeline Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify feature types\n",
        "numeric_features = [\n",
        "    \"Temperature(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\",\n",
        "    \"Wind_Speed(mph)\", \"Precipitation(in)\", \"Distance(mi)\",\n",
        "    \"Hour\", \"DayOfWeek\", \"Month\"\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    \"Traffic_Signal\", \"Junction\", \"Crossing\", \"Stop\", \"Station\",\n",
        "    \"Amenity\", \"Bump\", \"Give_Way\", \"Railway\", \"Roundabout\",\n",
        "    \"IsRushHour\", \"IsWeekend\", \"Sunrise_Sunset\", \"Weather_Condition\"\n",
        "]\n",
        "\n",
        "# Preprocessing transformers\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"Preprocessing pipeline created successfully!\")\n",
        "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
        "print(f\"Categorical features: {len(categorical_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For Binary Classification\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
        "    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "# For Multiclass Classification\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
        "    X, y_multiclass, test_size=0.2, random_state=42, stratify=y_multiclass\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAIN-TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training samples: {X_train_bin.shape[0]:,}\")\n",
        "print(f\"Testing samples: {X_test_bin.shape[0]:,}\")\n",
        "print(f\"\\nTraining set High Severity rate: {y_train_bin.mean():.2%}\")\n",
        "print(f\"Testing set High Severity rate: {y_test_bin.mean():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Define All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"BUILDING MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Dictionary to store all models\n",
        "binary_models = {}\n",
        "multiclass_models = {}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# BINARY CLASSIFICATION MODELS (High vs Low Severity)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# 1. Logistic Regression\n",
        "binary_models['Logistic Regression'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(\n",
        "        max_iter=1000, \n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 2. Random Forest\n",
        "binary_models['Random Forest'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        min_samples_split=100,\n",
        "        min_samples_leaf=50,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Gradient Boosting\n",
        "binary_models['Gradient Boosting'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 4. Decision Tree\n",
        "binary_models['Decision Tree'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(\n",
        "        max_depth=10,\n",
        "        min_samples_split=100,\n",
        "        min_samples_leaf=50,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 5. K-Nearest Neighbors\n",
        "binary_models['KNN'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', KNeighborsClassifier(\n",
        "        n_neighbors=50,\n",
        "        weights='distance',\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 6. Random Forest with SMOTE (for comparison)\n",
        "binary_models['Random Forest + SMOTE'] = ImbPipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# MULTICLASS CLASSIFICATION MODELS (Severity 1, 2, 3, 4)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# 1. Logistic Regression (Multinomial)\n",
        "multiclass_models['Logistic Regression'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(\n",
        "        multi_class='multinomial',\n",
        "        solver='lbfgs',\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 2. Random Forest\n",
        "multiclass_models['Random Forest'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        min_samples_split=100,\n",
        "        min_samples_leaf=50,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Gradient Boosting\n",
        "multiclass_models['Gradient Boosting'] = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(f\"\\n✓ Binary Classification Models: {len(binary_models)}\")\n",
        "print(f\"✓ Multiclass Classification Models: {len(multiclass_models)}\")\n",
        "print(\"\\nAll models ready for training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train and Evaluate Binary Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"BINARY CLASSIFICATION: TRAINING & EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "binary_results = []\n",
        "\n",
        "for name, model in binary_models.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Training {name}...\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # Train\n",
        "    model.fit(X_train_bin, y_train_bin)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test_bin)\n",
        "    y_pred_proba = None\n",
        "    \n",
        "    # Get prediction probabilities if available\n",
        "    if hasattr(model.named_steps['classifier'], 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X_test_bin)[:, 1]\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test_bin, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_test_bin, y_pred, average='binary'\n",
        "    )\n",
        "    \n",
        "    # ROC AUC if probabilities available\n",
        "    roc_auc = None\n",
        "    if y_pred_proba is not None:\n",
        "        roc_auc = roc_auc_score(y_test_bin, y_pred_proba)\n",
        "    \n",
        "    # Store results\n",
        "    binary_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': roc_auc\n",
        "    })\n",
        "    \n",
        "    print(f\"  ✓ Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  ✓ Precision: {precision:.4f}\")\n",
        "    print(f\"  ✓ Recall:    {recall:.4f}\")\n",
        "    print(f\"  ✓ F1-Score:  {f1:.4f}\")\n",
        "    if roc_auc:\n",
        "        print(f\"  ✓ ROC-AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "# Create results dataframe\n",
        "binary_results_df = pd.DataFrame(binary_results)\n",
        "binary_results_df = binary_results_df.sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BINARY CLASSIFICATION RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "display(binary_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Train and Evaluate Multiclass Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"MULTICLASS CLASSIFICATION: TRAINING & EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "multiclass_results = []\n",
        "\n",
        "for name, model in multiclass_models.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Training {name}...\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # Train\n",
        "    model.fit(X_train_multi, y_train_multi)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test_multi)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test_multi, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_test_multi, y_pred, average='weighted'\n",
        "    )\n",
        "    \n",
        "    # Store results\n",
        "    multiclass_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1\n",
        "    })\n",
        "    \n",
        "    print(f\"  ✓ Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  ✓ Precision: {precision:.4f}\")\n",
        "    print(f\"  ✓ Recall:    {recall:.4f}\")\n",
        "    print(f\"  ✓ F1-Score:  {f1:.4f}\")\n",
        "\n",
        "# Create results dataframe\n",
        "multiclass_results_df = pd.DataFrame(multiclass_results)\n",
        "multiclass_results_df = multiclass_results_df.sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MULTICLASS CLASSIFICATION RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "display(multiclass_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Detailed Analysis of Best Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best Binary Model\n",
        "best_binary_model_name = binary_results_df.iloc[0]['Model']\n",
        "best_binary_model = binary_models[best_binary_model_name]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"BEST BINARY MODEL: {best_binary_model_name}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "y_pred_best_bin = best_binary_model.predict(X_test_bin)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_bin, y_pred_best_bin, \n",
        "                          target_names=['Low Severity (1-2)', 'High Severity (3-4)']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best Multiclass Model\n",
        "best_multi_model_name = multiclass_results_df.iloc[0]['Model']\n",
        "best_multi_model = multiclass_models[best_multi_model_name]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"BEST MULTICLASS MODEL: {best_multi_model_name}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "y_pred_best_multi = best_multi_model.predict(X_test_multi)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_multi, y_pred_best_multi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Comprehensive Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization figure\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "\n",
        "# 1. Binary Model Comparison\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "binary_results_df.plot(x='Model', y=['Accuracy', 'Precision', 'Recall', 'F1-Score'], \n",
        "                       kind='bar', ax=ax1, rot=45)\n",
        "ax1.set_title('Binary Classification - Model Comparison', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Score')\n",
        "ax1.legend(loc='lower right', fontsize=8)\n",
        "ax1.set_ylim([0, 1])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 2. Multiclass Model Comparison\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "multiclass_results_df.plot(x='Model', y=['Accuracy', 'Precision', 'Recall', 'F1-Score'], \n",
        "                           kind='bar', ax=ax2, rot=45)\n",
        "ax2.set_title('Multiclass Classification - Model Comparison', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Score')\n",
        "ax2.legend(loc='lower right', fontsize=8)\n",
        "ax2.set_ylim([0, 1])\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 3. Binary Confusion Matrix\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "cm_bin = confusion_matrix(y_test_bin, y_pred_best_bin)\n",
        "sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Blues', ax=ax3,\n",
        "            xticklabels=['Low', 'High'], yticklabels=['Low', 'High'])\n",
        "ax3.set_title(f'Binary Confusion Matrix\\n{best_binary_model_name}', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('Actual'